# Training configuration for talking avatars 
checkpoint_path: "ltxv-2b-0.9.6-dev-04-25.safetensors"
precision: "bf16"
sampler: "uniform"  # options: "uniform", "linear-quadratic", "from_checkpoint"

# Training-specific parameters
train:
  condition_latents_dir: "../../data_avatar021225/condition_latents"  # FaceFormer audio latents (*_ff.npy)
  encoder_latents_dir: "../../data_avatar021225/encoder_latents"  # VAE encoder latents (*.pt)

  val_condition_latents_dir: "../../data_avatar021225/val_condition_latents"  # FaceFormer audio latents (*_ff.npy)
  val_encoder_latents_dir: "../../data_avatar021225/val_encoder_latents"  # VAE encoder latents (*.pt)
  videos: "../../data_avatar021225/video_clips" 

  output_dir: "../avatars_checkpoints"
  
  batch_size: 8
  num_epochs: 500
  learning_rate: 1e-4
  
  # Memory optimization
  gradient_checkpointing: false  
  gradient_accumulation_steps: 16
  
  # Model sharding (for multi-GPU training)
  use_deepspeed: false  
  deepspeed_config: "../configs/ds_config_zero3.json"  # DeepSpeed ZeRO-2 or ZeRO-3
  
  # Logging & Experiment Tracking
  wandb_project: "ltx-video-avatars"
  wandb_run_name: null 
  log_every_n_steps: 20  
  save_every_n_epochs: 10
  
  # LoRA parameters
  lora_rank: 32
  lora_alpha: 32
  
  # Rectified Flow scheduler (training)
  rf_num_train_timesteps: 1000
  rf_sampler: "Uniform" 
  rf_shifting: null  # optional: "simple", "interpolate", or null
  rf_base_resolution: 1024 
  rf_target_shift_terminal: null 
  rf_shift: null 
  
  # SD3-style log-normal timestep sampling
  rf_log_normal_mu: -0.5 
  rf_log_normal_sigma: 1  
  rf_quantile_min: 0.005  
  rf_quantile_max: 0.999 
           # uniform t ~ U(0, t_max) for last-step objective

